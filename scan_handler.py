from aiogram import Router, F
from aiogram.fsm.state import StatesGroup, State
from aiogram import Bot
import os
from dotenv import load_dotenv
from aiogram import types
from aiogram.fsm.context import FSMContext
import json
import asyncio
from funcs import *
from kb import *
from gpt import process_resume, create_new_resume, fix_color_formatting
from google_sheet import *
from teleton_client import search_id 
from google_disk import GoogleDriveManager
from maps_for_sheet import *
from docx_generator import create_and_upload_docx_to_drive, save_docx_locally_and_upload

load_dotenv()
bot = Bot(token=os.getenv('BOT_TOKEN'))
scan_router = Router()
gm = GoogleDriveManager(credentials_path="oauth.json")
ADMIN_ID = int(os.getenv('ADMIN_ID'))

class Scan(StatesGroup):
    waiting_for_resume = State()
    processing_files = State() # –ù–æ–≤—ã–π —Å—Ç–µ–π—Ç –¥–ª—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏

class DeleteRecord(StatesGroup):
    waiting_for_id = State()


@scan_router.callback_query(F.data == 'scan')
async def send_welcome(callback: types.CallbackQuery, state: FSMContext):
    await callback.message.delete()
    #await callback.message.answer("–û—Ç–ø—Ä–∞–≤—å—Ç–µ id –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ üÜîXX-xxxx –∏–ª–∏ üÜîxxxx")
    await callback.message.answer("–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ä–µ–∑—é–º–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ PDF/DOCX/RTF/TXT")
    await state.set_state(Scan.waiting_for_resume)


# @scan_router.message(Scan.waiting_for_id)
# async def send_welcome(message: types.Message, state: FSMContext):
#     id = message.text
#     vacancy_text = await search_id(id, client)
#     if isinstance(vacancy_text, Exception):
#         await message.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–µ–∑—é–º–µ!")
#     elif vacancy_text:
#         await message.answer(f'–í–∞–∫–∞–Ω—Å–∏—è —Å ID {id} –Ω–∞–π–¥–µ–Ω–∞!')
#         await message.answer("–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ä–µ–∑—é–º–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ pdf/docx")
#         await state.update_data(vacancy_text=vacancy_text)
#         await state.set_state(Scan.waiting_for_resume)
#     else:
#         await message.answer(f"‚ùå –†–µ–∑—é–º–µ —Å ID {id} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
        

@scan_router.message(F.document, Scan.waiting_for_resume)
async def handle_resume_document(message: types.Message, state: FSMContext):
    data = await state.get_data()
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
    documents = data.get("documents", [])
    documents.append(message.document)

    # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –≤ —Å–µ—Ä–∏–∏, –∑–∞–ø—É—Å–∫–∞–µ–º —Ç–∞–π–º–µ—Ä
    if len(documents) == 1:
        await state.update_data(documents=documents)
        # –ñ–¥–µ–º 2 —Å–µ–∫—É–Ω–¥—ã, —á—Ç–æ–±—ã —Å–æ–±—Ä–∞—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
        asyncio.create_task(process_files_after_delay(message, state))
    else:
        # –ü—Ä–æ—Å—Ç–æ –æ–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏
        await state.update_data(documents=documents)


async def process_files_after_delay(message: types.Message, state: FSMContext):
    await asyncio.sleep(2)  # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ —Å–±–æ—Ä –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

    data = await state.get_data()
    documents = data.get("documents", [])
    
    # –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç, –≤—ã—Ö–æ–¥–∏–º
    if not documents:
        return

    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã
    await state.set_state(Scan.processing_files)
    
    total_files = len(documents)
    await message.answer(f"ü§ñ –ü—Ä–∏–Ω—è—Ç–æ {total_files} —Ä–µ–∑—é–º–µ. –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")

    processed_count = 0
    error_count = 0

    for document in documents:
        try:
            await process_single_resume(message, document)
            processed_count += 1
        except Exception as e:
            error_count += 1
            error_msg = str(e)
            if len(error_msg) > 3000:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ
                error_msg = error_msg[:3000] + "..."
            await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ `{document.file_name}`: {error_msg}")
    
    summary_message = f"‚ú® –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\n\n‚úÖ –£—Å–ø–µ—à–Ω–æ: {processed_count}\n‚ùå –° –æ—à–∏–±–∫–∞–º–∏: {error_count}"
    await message.answer(summary_message, reply_markup=await start_kb())

    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è
    await state.update_data(documents=[])
    await state.set_state(Scan.waiting_for_resume)
    await message.answer("‚úÖ –ì–æ—Ç–æ–≤–æ! –ú–æ–∂–µ—Ç–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–ª–µ–¥—É—é—â—É—é –ø–∞—á–∫—É —Ä–µ–∑—é–º–µ –∏–ª–∏ –≤–µ—Ä–Ω—É—Ç—å—Å—è –≤ –º–µ–Ω—é.")


async def process_single_resume(message: types.Message, document: types.Document):
    if not document:
        
        await message.answer("–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ä–µ–∑—é–º–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ PDF/DOCX/RTF/TXT")
        return
    file_info = await bot.get_file(document.file_id)
    file_path = file_info.file_path
    file_name = document.file_name
    resume_id = generate_random_id()
    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –ª–æ–∫–∞–ª—å–Ω–æ
    local_file_path = f"downloads/{file_name}"
    os.makedirs("downloads", exist_ok=True)
    await bot.download_file(file_path, destination=local_file_path)
    ext = file_name.split(".")[-1].lower()

    if ext == "pdf":
        text = await process_pdf(local_file_path)
        
        await message.answer(f"‚úÖ PDF –ø—Ä–∏–Ω—è—Ç –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω\n\n –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ç–µ–∫—Å—Ç...")
    elif ext == "docx":
        text = await process_docx(local_file_path)
        
        await message.answer(f"‚úÖ DOCX –ø—Ä–∏–Ω—è—Ç –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω\n\n –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ç–µ–∫—Å—Ç...")
    elif ext == "rtf":
        text = await process_rtf(local_file_path)
        
        await message.answer(f"‚úÖ RTF –ø—Ä–∏–Ω—è—Ç –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω\n\n –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ç–µ–∫—Å—Ç...")
    elif ext == "txt":
        text = await process_txt(local_file_path)
        
        await message.answer(f"‚úÖ TXT –ø—Ä–∏–Ω—è—Ç –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω\n\n –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ç–µ–∫—Å—Ç...")
    else:
        await message.answer("‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ PDF, DOCX, RTF –∏ TXT —Ñ–∞–π–ª—ã")
        return
    
    rekruter_username = message.from_user.username
    user_id = message.from_user.id
    
    resume_data = process_resume(text, document.file_name)
    if not resume_data:
        message.answer('–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ')
        return
    first_name = resume_data.get("firstName", {}).get('–ù–∞ —Ä—É—Å—Å–∫–æ–º') if resume_data.get("firstName") else None
    first_name_en = resume_data.get("firstName", {}).get('–ù–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º') if resume_data.get("firstName") else None
    last_name = resume_data.get("lastName", {}).get('–ù–∞ —Ä—É—Å—Å–∫–æ–º') if resume_data.get("lastName") else None
    last_name_en = resume_data.get("lastName", {}).get('–ù–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º') if resume_data.get("lastName") else None
    patronymic = resume_data.get("patronymic", {}).get('–ù–∞ —Ä—É—Å—Å–∫–æ–º') if resume_data.get("patronymic") else None
    patronymic_en = resume_data.get("patronymic", {}).get('–ù–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º') if resume_data.get("patronymic") else None
    date_of_birth = resume_data.get("dateOfBirth")
    languages = resume_data.get("languages")
    if first_name is None and first_name_en is None:
        await message.answer("‚ùå –í —Ä–µ–∑—é–º–µ –Ω–µ—Ç –∏–º–µ–Ω–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞ —É—Ç–æ—á–Ω–∏—Ç–µ –µ–≥–æ")
        return
    if last_name is None and last_name_en is None:
        await message.answer("‚ùå –í —Ä–µ–∑—é–º–µ –Ω–µ—Ç —Ñ–∞–º–∏–ª–∏–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞ —É—Ç–æ—á–Ω–∏—Ç–µ –µ–≥–æ")
        return
    if patronymic is None:
        await message.answer("‚ùå –í —Ä–µ–∑—é–º–µ –Ω–µ—Ç –æ—Ç—á–µ—Å—Ç–≤–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞ —É—Ç–æ—á–Ω–∏—Ç–µ –µ–≥–æ")
        
    if date_of_birth is None:
        await message.answer("‚ùå –í —Ä–µ–∑—é–º–µ –Ω–µ—Ç –¥–∞—Ç—ã —Ä–æ–∂–¥–µ–Ω–∏—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞ —É—Ç–æ—á–Ω–∏—Ç–µ –µ–≥–æ")
        
        
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —è–∑—ã–∫–æ–≤
    if languages is None or not languages or all(not v for v in languages.values() if isinstance(v, (str, bool))):
        await message.answer("‚ùå –í —Ä–µ–∑—é–º–µ –Ω–µ—Ç —Å–≤–µ–¥–µ–Ω–∏–π –æ–± —è–∑—ã–∫–∞—Ö. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞ —É—Ç–æ—á–Ω–∏—Ç–µ —Å–≤–µ–¥–µ–Ω–∏—è –æ–± —è–∑—ã–∫–∞—Ö")
        
    is_duplicate = None
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –§–ò
    if first_name and last_name:
        is_duplicate = check_duplicate_by_fio(first_name, last_name)
    elif first_name_en and last_name_en:
        is_duplicate = check_duplicate_by_fio(first_name_en, last_name_en)
    
    if is_duplicate:
        await message.answer(f"‚ö†Ô∏è –ö–∞–Ω–¥–∏–¥–∞—Ç {last_name} {first_name} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö!")
        return
    
    new_resume_data = create_new_resume(text, resume_id)
    
    # –û—á–∏—â–∞–µ–º markdown —Å–∏–º–≤–æ–ª—ã –∏–∑ –æ–±–µ–∏—Ö –≤–µ—Ä—Å–∏–π –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º —Ü–≤–µ—Ç–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    if isinstance(new_resume_data, dict):
        new_resume_russian = new_resume_data.get('russian', '')
        new_resume_english = new_resume_data.get('english', '')
        
        # –ë–æ–ª–µ–µ –∞–∫–∫—É—Ä–∞—Ç–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ markdown –±–µ–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
        import re
        new_resume_russian = re.sub(r'\*{1,2}([^*]+)\*{1,2}', r'\1', new_resume_russian)
        new_resume_russian = re.sub(r'#{1,6}\s*', '', new_resume_russian)
        new_resume_english = re.sub(r'\*{1,2}([^*]+)\*{1,2}', r'\1', new_resume_english)
        new_resume_english = re.sub(r'#{1,6}\s*', '', new_resume_english)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ü–≤–µ—Ç–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        new_resume_russian = fix_color_formatting(new_resume_russian)
        new_resume_english = fix_color_formatting(new_resume_english)
        
        # –£–±–∏—Ä–∞–µ–º —Å–∏–º–≤–æ–ª—ã ‚ñ† –∏ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        new_resume_russian = new_resume_russian.replace('‚ñ†', '').replace('\ufffd', '').replace('\u25a0', '')
        new_resume_english = new_resume_english.replace('‚ñ†', '').replace('\ufffd', '').replace('\u25a0', '')
    else:
        # Fallback –¥–ª—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
        new_resume_russian = str(new_resume_data)
        new_resume_english = new_resume_russian
        
        # –ë–æ–ª–µ–µ –∞–∫–∫—É—Ä–∞—Ç–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ markdown
        import re
        new_resume_russian = re.sub(r'\*{1,2}([^*]+)\*{1,2}', r'\1', new_resume_russian)
        new_resume_russian = re.sub(r'#{1,6}\s*', '', new_resume_russian)
        new_resume_english = re.sub(r'\*{1,2}([^*]+)\*{1,2}', r'\1', new_resume_english)
        new_resume_english = re.sub(r'#{1,6}\s*', '', new_resume_english)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ü–≤–µ—Ç–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        new_resume_russian = fix_color_formatting(new_resume_russian)
        new_resume_english = fix_color_formatting(new_resume_english)
        
        # –£–±–∏—Ä–∞–µ–º —Å–∏–º–≤–æ–ª—ã ‚ñ† –∏ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        new_resume_russian = new_resume_russian.replace('‚ñ†', '').replace('\ufffd', '').replace('\u25a0', '')
        new_resume_english = new_resume_english.replace('‚ñ†', '').replace('\ufffd', '').replace('\u25a0', '')
    if not resume_data:
        await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–µ–∑—é–º–µ")
        return
    
    await message.answer(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∏–∑–≤–ª–µ—á–µ–Ω—ã!")
    
    
    
    first = resume_data.get("firstName")['–ù–∞ —Ä—É—Å—Å–∫–æ–º']
    last = resume_data.get("lastName")['–ù–∞ —Ä—É—Å—Å–∫–æ–º']
    first_en = resume_data.get("firstName")['–ù–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º']
    last_en = resume_data.get("lastName")['–ù–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º']
    

    if first and last:
        folder_name = f"{resume_id}\n{first} {last}"
    elif first:
        folder_name = f"{resume_id}\n{first}"
    elif last:
        folder_name = f"{resume_id}\n{last}"
    else:
        folder_name = f"{resume_id}\n–†–µ–∑—é–º–µ"
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É
    folder_id = gm.get_or_create_folder(folder_name)
    if not folder_id:
        await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ Google Drive")
        return
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª –∏ –ø–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ñ–∞–π–ª–µ
    upload_result = gm.upload_file(
        file_path=local_file_path,
        folder_id=folder_id,
        file_name=file_name,
    )
    
    if upload_result.get('success'):
        file_id = upload_result.get('file_id')
        file_url = upload_result.get('web_link')
        
        # –î–µ–ª–∞–µ–º —Ñ–∞–π–ª –æ–±—â–µ–¥–æ—Å—Ç—É–ø–Ω—ã–º
        if file_id:
            permissions_set = gm.set_file_permissions(file_id, permission_type='reader', role='anyone')
            if permissions_set:
                print(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Google Drive –∏ —Å–¥–µ–ª–∞–Ω –æ–±—â–µ–¥–æ—Å—Ç—É–ø–Ω—ã–º!\nüîó")
            else:
                print(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Google Drive, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å –µ–≥–æ –æ–±—â–µ–¥–æ—Å—Ç—É–ø–Ω—ã–º\nüîó")
        elif file_url:
            print(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Google Drive!\nüîó")
        else:
            print(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Google Drive!")
    else:
        await message.answer(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –≤ Google Drive: {upload_result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ –∫–∞–∫ Word –¥–æ–∫—É–º–µ–Ω—Ç—ã (—Ä—É—Å—Å–∫–∞—è –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∞—è –≤–µ—Ä—Å–∏–∏)
    new_resume_url_russian = None
    new_resume_url_english = None
    
    if new_resume_russian:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä—É—Å—Å–∫—É—é –≤–µ—Ä—Å–∏—é
        new_resume_filename_ru = f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ_RU_{file_name.replace('.pdf', '').replace('.docx', '')}"
        new_resume_title_ru = f"{first} {last}" if first and last else "–†–µ–∑—é–º–µ (RU)"
        print(new_resume_russian)
        
        docx_upload_result_ru = create_and_upload_docx_to_drive(
            text=new_resume_russian,
            file_name=new_resume_filename_ru,
            folder_name=folder_name,
            title=new_resume_title_ru,
            credentials_path="oauth.json"
        )
        
        if docx_upload_result_ru.get('success'):
            new_resume_url_russian = docx_upload_result_ru.get('web_link')
            print(f"‚úÖ –†—É—Å—Å–∫–æ–µ —Ä–µ–∑—é–º–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –≤ Word!\nüîó")
        else:
            await message.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä—É—Å—Å–∫–æ–µ —Ä–µ–∑—é–º–µ: {docx_upload_result_ru.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
    
    if new_resume_english:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–Ω–≥–ª–∏–π—Å–∫—É—é –≤–µ—Ä—Å–∏—é
        new_resume_filename_en = f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ_EN_{file_name.replace('.pdf', '').replace('.docx', '')}"
        new_resume_title_en = f"{first_en} {last_en}" if first_en and last_en else "Resume (EN)"
        print(new_resume_english)
        docx_upload_result_en = create_and_upload_docx_to_drive(
            text=new_resume_english,
            file_name=new_resume_filename_en,
            folder_name=folder_name,
            title=new_resume_title_en,
            credentials_path="oauth.json"
        )
        
        if docx_upload_result_en.get('success'):
            new_resume_url_english = docx_upload_result_en.get('web_link')
            print(f"‚úÖ –ê–Ω–≥–ª–∏–π—Å–∫–æ–µ —Ä–µ–∑—é–º–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –≤ Word!\nüîó")
        else:
            await message.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞–Ω–≥–ª–∏–π—Å–∫–æ–µ —Ä–µ–∑—é–º–µ: {docx_upload_result_en.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ Google —Ç–∞–±–ª–∏—Ü—É
    
    rate_sng_for_main_table = None
    rate_eur_for_main_table = None
    salary_expectations = None
    
    salary = resume_data.get("salaryExpectations")
    salaru = salary.get('amount') if salary else None
    salary_valuta = salary.get('currency') if salary else None
    
    if salaru and salary_valuta:
        
        salary_expectations = salary.get('amount') + " " + salary.get('currency')
        
        salaru = int(salaru)
        if salary_valuta == "RUB":
            search_col = "B"
        elif salary_valuta == "BYN":
            search_col = "E"
        elif salary_valuta == "USD":
            search_col = "C"
        elif salary_valuta == "EUR":
            search_col = "D"
        
        
            
        contract_data_sng = search_and_extract_values(search_col, salaru, ["M",'N','O','P'], "–†–∞—Å—Å—á–µ—Ç —Å—Ç–∞–≤–∫–∏ (—à—Ç–∞—Ç/–∫–æ–Ω—Ç—Ä–∞–∫—Ç) –°–ù–ì")
        ip_data_sng = search_and_extract_values(search_col, salaru, ["M",'N','O','P'], "–†–∞—Å—Å—á–µ—Ç —Å—Ç–∞–≤–∫–∏ (–ò–ü) –°–ù–ì")
        samozanyatii_data_sng = search_and_extract_values(search_col, salaru, ["M",'N','O','P'], "–†–∞—Å—Å—á–µ—Ç —Å—Ç–∞–≤–∫–∏ (–°–∞–º–æ–∑–∞–Ω—è—Ç—ã–π) –°–ù–ì")
            
        
        contract_data_es = search_and_extract_values(search_col, salaru, ['M','N','O', 'P'], "–†–∞—Å—Å—á–µ—Ç —Å—Ç–∞–≤–∫–∏ (—à—Ç–∞—Ç/–∫–æ–Ω—Ç—Ä–∞–∫—Ç) –ï–°/–°–®–ê")
        ip_data_es = search_and_extract_values(search_col, salaru, ["M",'N','O','P'], "–†–∞—Å—Å—á–µ—Ç —Å—Ç–∞–≤–∫–∏ (–ò–ü) –ï–°/–°–®–ê")
        samozanyatii_data_es = search_and_extract_values(search_col, salaru, ["M",'N','O','P'], "–†–∞—Å—Å—á–µ—Ç —Å—Ç–∞–≤–∫–∏ (–°–∞–º–æ–∑–∞–Ω—è—Ç—ã–π) –ï–°/–°–®–ê")
        print(contract_data_es)
        print(ip_data_es)
        print(samozanyatii_data_es)
        print(contract_data_sng)
        print(ip_data_sng)
        print(samozanyatii_data_sng)
    try:
        data_for_sng_rate_sheet = {
            'id' : resume_id,
            'contract_data_sng_eur': contract_data_sng.get('O'),
            'contract_data_sng_usd': contract_data_sng.get('N'),
            'contract_data_sng_rub': contract_data_sng.get('M'),
            'contract_data_sng_byn': contract_data_sng.get('P'),
            'ip_data_sng_eur': ip_data_sng.get('O'),
            'ip_data_sng_usd': ip_data_sng.get('N'),
            'ip_data_sng_rub': ip_data_sng.get('M'),
            'ip_data_sng_byn': ip_data_sng.get('P'),
            'samozanyatii_data_sng_eur': samozanyatii_data_sng.get('O'),
            'samozanyatii_data_sng_usd': samozanyatii_data_sng.get('N'),
            'samozanyatii_data_sng_rub': samozanyatii_data_sng.get('M'),
            'samozanyatii_data_sng_byn': samozanyatii_data_sng.get('P'),
        }
        
        date_for_eur_rate_sheet = {
            'id' : resume_id,
            'contract_data_eur': contract_data_es.get('O'),
            'contract_data_usd': contract_data_es.get('N'),
            'contract_data_rub': contract_data_es.get('M'),
            'contract_data_byn': contract_data_es.get('P'),
            'ip_data_eur': ip_data_es.get('O'),
            'ip_data_usd': ip_data_es.get('N'),
            'ip_data_rub': ip_data_es.get('M'),
            'ip_data_byn': ip_data_es.get('P'),
            'samozanyatii_data_eur': samozanyatii_data_es.get('O'),
            'samozanyatii_data_usd': samozanyatii_data_es.get('N'),
            'samozanyatii_data_rub': samozanyatii_data_es.get('M'),
            'samozanyatii_data_byn': samozanyatii_data_es.get('P'),
        }
        date_for_eu_sng_rates = {
            '–†–µ–π—Ç –¥–ª—è –ó–∞–∫–∞–∑—á–∏–∫–∞ (–°–ù–ì)' : data_for_sng_rate_sheet,
            '–†–µ–π—Ç –¥–ª—è –ó–∞–∫–∞–∑—á–∏–∫–∞ (–ï–°/–°–®–ê)' : date_for_eur_rate_sheet,
            
        }
        
        for k, v in date_for_eu_sng_rates.items():
            print(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ {v} –≤ Google —Ç–∞–±–ª–∏—Ü—É...")
            success = await add_data_to_worksheet(v, worksheet_name=k)
            if success:
                print(f"üìä {k} –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ Google —Ç–∞–±–ª–∏—Ü—É!")
            else:
                await message.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å {k} –≤ Google —Ç–∞–±–ª–∏—Ü—É. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.")
                
                
        rate_sng_for_main_table = f"–®—Ç–∞—Ç/–∫–æ–Ω—Ç—Ä–∞–∫—Ç-{data_for_sng_rate_sheet.get('contract_data_sng_rub')}\n–ò–ü-{data_for_sng_rate_sheet.get('ip_data_sng_rub')}\n–°–∞–º–æ–∑–∞–Ω—è—Ç—ã–π-{data_for_sng_rate_sheet.get('samozanyatii_data_sng_rub')}"
        rate_eur_for_main_table = f"–®—Ç–∞—Ç/–∫–æ–Ω—Ç—Ä–∞–∫—Ç-{date_for_eur_rate_sheet.get('contract_data_usd')}\n–ò–ü-{date_for_eur_rate_sheet.get('ip_data_usd')}\n–°–∞–º–æ–∑–∞–Ω—è—Ç—ã–π-{date_for_eur_rate_sheet.get('samozanyatii_data_usd')}"
        
        
    except Exception as e:
        await message.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ —Å—Ç–∞–≤–∫–∞—Ö –≤ Google —Ç–∞–±–ª–∏—Ü—É. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.")       
    else:
        salary = None
        
    
    data_for_resume_sheet = {
        "resume_id": resume_id,
        "last_name": resume_data.get("lastName", {}).get("–ù–∞ —Ä—É—Å—Å–∫–æ–º") or resume_data.get("lastName", {}).get("–ù–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º"),
        "first_name": resume_data.get("firstName", {}).get("–ù–∞ —Ä—É—Å—Å–∫–æ–º") or resume_data.get("firstName", {}).get("–ù–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º"),
        "middle_name": (resume_data.get("patronymic") or {}).get("–ù–∞ —Ä—É—Å—Å–∫–æ–º") or (resume_data.get("patronymic") or {}).get("–ù–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º"),
        "specialization": resume_data.get("specialization"),
        "date_of_birth": resume_data.get("dateOfBirth"),
        "location" : ", ".join(filter(None, [
            resume_data.get('city') if isinstance(resume_data.get('city'), str) else ", ".join(resume_data.get('city', [])) if resume_data.get('city') else None,
            resume_data.get('location') if isinstance(resume_data.get('location'), str) else ", ".join(resume_data.get('location', [])) if resume_data.get('location') else None
        ])) or "–Ω–µ —É–∫–∞–∑–∞–Ω–æ",
        "grade": ", ".join([k for k, v in resume_data.get("grade", {}).items() if v]),
        "total_experience": resume_data.get("totalExperience"),
        "special_experience": resume_data.get("specialExperience"),
        'program_languages': ", ".join([k for k, v in resume_data.get('programmingLanguages', {}).items() if v]),
        'frameworks': ", ".join([k for k, v in resume_data.get('frameworks', {}).items() if v]),
        'technologies': ", ".join([k for k, v in resume_data.get('technologies', {}).items() if v]),
        'project_industries' : ", ".join([k for k, v in resume_data.get('projectIndustries', {}).items() if v]),
        'languague' : ", ".join([f"{k}: {v}" for k, v in resume_data.get('languages', {}).items() if v and v != False]),
        'portfolio' : ", ".join([k for k, v in resume_data.get('portfolio', {}).items() if v]),
        'contacts': '\n'.join(filter(None, [
            resume_data.get('contacts', {}).get('phone'),
            resume_data.get('contacts', {}).get('email'),
            resume_data.get('contacts', {}).get('linkedin'),
            resume_data.get('contacts', {}).get('telegram'),
            resume_data.get('contacts', {}).get('skype'),
            resume_data.get('contacts', {}).get('github'),
            resume_data.get('contacts', {}).get('gitlab'),
            resume_data.get('contacts', {}).get('whatsapp'),
            resume_data.get('contacts', {}).get('viber'),
            resume_data.get('contacts', {}).get('discord'),
            resume_data.get('contacts', {}).get('slack'),
            resume_data.get('contacts', {}).get('microsoftTeams'),
            resume_data.get('contacts', {}).get('zoom'),
            resume_data.get('contacts', {}).get('googleMeet'),
            resume_data.get('contacts', {}).get('facebook'),
            resume_data.get('contacts', {}).get('instagram'),
            resume_data.get('contacts', {}).get('twitter'),
            resume_data.get('contacts', {}).get('vk'),
            resume_data.get('contacts', {}).get('tiktok'),
            resume_data.get('contacts', {}).get('reddit'),
            resume_data.get('contacts', {}).get('stackoverflow'),
            resume_data.get('contacts', {}).get('habrCareer')
        ])),
        
        "salary_expectations": salary_expectations,
        "rate_sng": rate_sng_for_main_table,
        "rate_eur": rate_eur_for_main_table,
        "availability": ", ".join([k for k, v in resume_data.get('availability', {}).items() if v]) if isinstance(resume_data.get('availability'), dict) else resume_data.get('availability', ''),
        "date_of_exit": ".",
        'resume_url' : file_url,
        'new_resume_url_russian' : new_resume_url_russian or '-',
        'new_resume_url_english' : new_resume_url_english or '-',
        'rekruiter_username' : '@' + rekruter_username,
        'date_add_for_rekruiter' : datetime.now().strftime("%Y-%m-%d %H:%M:%S") if user_id != ADMIN_ID else '-',
        'date_add_for_admin' : datetime.now().strftime("%Y-%m-%d %H:%M:%S") if user_id == ADMIN_ID else '-',
    }
    
    data_for_name_sheet = build_row(resume_id, resume_data.get("firstName"), NAME_MAP)
    
    data_for_surname_sheet = build_row(resume_id, resume_data.get("lastName"), SURNAME_MAP)
    
    data_for_roles_sheet = build_row_symbols(resume_id, resume_data.get("roles"), ROLES_MAP)
    
    data_for_location_sheet = {
        "resume_id": resume_id,
        "location": resume_data.get("location"),
        "city": resume_data.get("city"),
    }
    
    data_for_grade_sheet = build_row_symbols(resume_id, resume_data.get("grade"), GRADE_MAP)
    
    data_for_programm_lang_sheet = build_row_symbols(resume_id, resume_data.get("programmingLanguages"), PROGRAM_LANG_MAP)
    
    data_for_frameworks_sheet = build_row_symbols(resume_id, resume_data.get("frameworks"), FRAMEWORKS_MAP)
    
    data_for_tech_sheet = build_row_symbols(resume_id, resume_data.get("technologies"), TECH_MAP)
    
    data_for_project_industries_sheet = build_row_symbols(resume_id, resume_data.get("projectIndustries"), PRODUCT_INDUSTRIES_MAP)
    
    data_for_language_sheet = build_row(resume_id, resume_data.get('languages'), LANG_MAP)
    
    data_for_portfolio_sheet = build_row(resume_id, resume_data.get("portfolio"), PORTFOLIO_MAP)
    
    data_for_work_time_sheet = build_row_symbols(resume_id, resume_data.get('workTime'), WORK_TIME_MAP)
    
    data_for_work_form_sheet = build_row_symbols(resume_id, resume_data.get('workForm'), WORK_FORM_MAP)
    
    data_for_contacts_sheet = build_row(resume_id, resume_data.get('contacts'), CONTACTS_MAP)
    
    data_for_avaliable_sheet = build_row_symbols(resume_id, resume_data.get('availability'), AVAILABILITY_MAP)

    
    
    data_for_table = {
        '–°–≤–æ–±–æ–¥–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã –Ω–∞ –∞—É—Ç—Å—Ç–∞—Ñ—Ñ': data_for_resume_sheet,
        '–§–∞–º–∏–ª–∏—è' : data_for_surname_sheet,
        '–ò–º—è' : data_for_name_sheet,
        '–î–æ–ª–∂–Ω–æ—Å—Ç–∏/–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏' : data_for_roles_sheet,
        '–õ–æ–∫–∞—Ü–∏—è' : data_for_location_sheet,
        '–ì—Ä–µ–π–¥—ã —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤' : data_for_grade_sheet,
        '–Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è' : data_for_programm_lang_sheet,
        'Frameworks & Libraries' : data_for_frameworks_sheet,
        '–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã' : data_for_tech_sheet,
        '–û—Ç—Ä–∞—Å–ª–∏ –ø—Ä–æ–µ–∫—Ç–æ–≤' : data_for_project_industries_sheet,
        '–ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ —è–∑—ã–∫–∏' : data_for_language_sheet,
        '–ü–æ—Ä—Ç—Ñ–æ–ª–∏–æ' : data_for_portfolio_sheet,
        '–§–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã' : data_for_work_time_sheet,
        '–§–æ—Ä–º–∞ —Ç—Ä—É–¥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞' : data_for_work_form_sheet,
        '–ö–æ–Ω—Ç–∞–∫—Ç—ã' : data_for_contacts_sheet,
        '–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤' : data_for_avaliable_sheet,
    }
  
    
    
    for k, v in data_for_table.items():
        rint(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ {v} –≤ Google —Ç–∞–±–ª–∏—Ü—É...")
        success = await add_data_to_worksheet(v, worksheet_name=k)
        if success:
            print(f"üìä {k} –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ Google —Ç–∞–±–ª–∏—Ü—É!")
        else:
            await message.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å {k} –≤ Google —Ç–∞–±–ª–∏—Ü—É. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.")
    
    os.remove(local_file_path)
    # –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± —É—Å–ø–µ—Ö–µ –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ –∫–æ–Ω—Ü–µ —Ü–∏–∫–ª–∞
    await message.answer(f"‚úÖ –†–µ–∑—é–º–µ '{document.file_name}' —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ!")


@scan_router.callback_query(F.data == 'delete_record')
async def show_delete_menu(callback: types.CallbackQuery, state: FSMContext):
    """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç ID –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è"""
    await callback.message.delete()
    await callback.message.answer("üóëÔ∏è –í–≤–µ–¥–∏—Ç–µ ID –∑–∞–ø–∏—Å–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è:")
    await state.set_state(DeleteRecord.waiting_for_id)


@scan_router.message(DeleteRecord.waiting_for_id)
async def process_delete_id(message: types.Message, state: FSMContext):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–≤–µ–¥–µ–Ω–Ω—ã–π ID –∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ"""
    await state.clear()
    resume_id = message.text.strip()

    # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —É–¥–∞–ª–µ–Ω–∏—è
    from aiogram.utils.keyboard import InlineKeyboardBuilder
    confirm_kb = InlineKeyboardBuilder()
    confirm_kb.button(text="‚úÖ –î–∞, —É–¥–∞–ª–∏—Ç—å", callback_data=f"confirm_delete_{resume_id}")
    confirm_kb.button(text="‚ùå –û—Ç–º–µ–Ω–∞", callback_data="cancel_delete")
    confirm_kb.adjust(1)

    await message.answer(
        f"‚ö†Ô∏è –í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ —É–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å—å —Å ID: {resume_id}?\n\n"
        f"–≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ —É–¥–∞–ª–∏—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏–∑ –≤—Å–µ—Ö –ª–∏—Å—Ç–æ–≤ —Ç–∞–±–ª–∏—Ü—ã –∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç–º–µ–Ω–µ–Ω–æ!",
        reply_markup=confirm_kb.as_markup()
    )


@scan_router.callback_query(F.data.startswith('confirm_delete_'))
async def confirm_delete_record(callback: types.CallbackQuery):
    """–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç —É–¥–∞–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏"""
    await callback.message.delete()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ callback_data
    resume_id = callback.data.replace('confirm_delete_', '')
    
    await callback.message.answer(f"üóëÔ∏è –£–¥–∞–ª—è—é –∑–∞–ø–∏—Å—å —Å ID: {resume_id}...")
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º —É–¥–∞–ª–µ–Ω–∏–µ
    success = delete_resume_by_id(resume_id)
    
    if success:
        await callback.message.answer(
            f"‚úÖ –ó–∞–ø–∏—Å—å —Å ID {resume_id} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞ –∏–∑ –≤—Å–µ—Ö –ª–∏—Å—Ç–æ–≤ —Ç–∞–±–ª–∏—Ü—ã!",
            reply_markup=await start_kb(),
            
        )
    else:
        await callback.message.answer(
            f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å—å —Å ID {resume_id}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Google Sheets.",
            reply_markup=await start_kb(),
            
        )


@scan_router.callback_query(F.data == 'cancel_delete')
async def cancel_delete(callback: types.CallbackQuery):
    """–û—Ç–º–µ–Ω—è–µ—Ç —É–¥–∞–ª–µ–Ω–∏–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"""
    await callback.message.delete()
    await callback.message.answer("‚ùå –£–¥–∞–ª–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ", reply_markup=await start_kb())


